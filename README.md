# Decision-tree-using-ID3-Algorithm
Implementation of Decision Tree using ID3 Algorithm for classification
In this project, a decision tree is designed using ID3 algorithm. A decision tree has nodes and leaf nodes for classification and prediction. ID3 algorithm splits the data into two parts. The splitting of data is done on the basis of information gain which in turn depends on entropy.
In order to design a decision tree using ID3 algorithm, information gain and entropy of each column is calculated. This is done by functions infmation_gain(data,data_a,data_b) and ent(col). 
To make a decision tree using ID3 algorithm, one has to find the dominant column or attribute among all columns or attributes of the dataset. This dominant column or attribute now becomes root node for succesive tree. The dominant column is selected on the basis of information gain. The column having high information gain is selected as dominant column. After selecting the dominant column, it is removed from the dataset and a new dataset is created. Same procedure is implemented till we get leaf nodes only. The value of each root node generated is stored in the form of a key of a dictionary. 
In order to apply the decision tree over test data, classify_example(example, tree) function is used. It first split the key of the dictionary and check the condition for the test data. If the conditon leads to leaf node, it classifies the data to a perticular class but if not, it enters to another dictionary and repeats the same process till it reaches to leaf node or a perticular label.
